#!/usr/bin/env python3
"""
ç¼“å­˜ä¼˜åŒ–æµ‹è¯•
éªŒè¯å†…å­˜æ„ŸçŸ¥ç¼“å­˜ç³»ç»Ÿçš„æ•ˆæœ
"""

import sys
import os
import gc
import time
import numpy as np
import tempfile
from pathlib import Path
from typing import Dict, List, Tuple
import logging

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path("../worker").absolute()))
sys.path.insert(0, str(Path("../src").absolute()))
sys.path.insert(0, str(Path(".").absolute()))

# å¯¼å…¥æµ‹è¯•æ¨¡å—
from test_memory_optimization import MemoryProfiler, memory_profiler

logger = logging.getLogger(__name__)

class CacheOptimizationTest:
    """ç¼“å­˜ä¼˜åŒ–æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.results = {}
    
    def test_cache_memory_management(self) -> Dict:
        """æµ‹è¯•ç¼“å­˜å†…å­˜ç®¡ç†"""
        print("\nğŸ” æµ‹è¯•ç¼“å­˜å†…å­˜ç®¡ç†...")
        
        results = {}
        
        # æµ‹è¯•ä¼ ç»Ÿç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        print("  æµ‹è¯•ä¼ ç»Ÿç¼“å­˜æ–¹æ³•...")
        try:
            with memory_profiler("traditional_cache") as profiler:
                profiler.start_monitoring()
                
                # æ¨¡æ‹Ÿå¤§é‡ç¼“å­˜æ“ä½œ
                cache_data = {}
                
                profiler.take_snapshot("before_cache_operations")
                
                # åˆ›å»ºå¤§é‡ç¼“å­˜æ•°æ®
                for i in range(1000):
                    key = f"test_key_{i}"
                    # åˆ›å»ºè¾ƒå¤§çš„æ•°æ®å¯¹è±¡
                    value = {
                        "data": np.random.random(1000).tolist(),
                        "metadata": {"index": i, "timestamp": time.time()},
                        "large_text": "x" * 1000
                    }
                    cache_data[key] = value
                    
                    if i % 100 == 0:
                        profiler.take_snapshot(f"after_{i}_entries")
                
                profiler.take_snapshot("after_all_cache_operations")
                
                # æ¸…ç†
                del cache_data
                gc.collect()
                profiler.take_snapshot("after_cleanup")
            
            peak = profiler.get_peak_memory()
            growth = profiler.get_memory_growth()
            
            results["traditional"] = {
                "peak_memory_mb": peak.rss_mb,
                "memory_growth_rate": growth,
                "success": True
            }
            
            print(f"    ä¼ ç»Ÿç¼“å­˜å³°å€¼å†…å­˜: {peak.rss_mb:.1f} MB")
            
        except Exception as e:
            print(f"    âŒ ä¼ ç»Ÿç¼“å­˜æµ‹è¯•å¤±è´¥: {e}")
            results["traditional"] = {"success": False, "error": str(e)}
        
        # æµ‹è¯•ä¼˜åŒ–ç¼“å­˜
        print("  æµ‹è¯•ä¼˜åŒ–ç¼“å­˜æ–¹æ³•...")
        try:
            with memory_profiler("optimized_cache") as profiler:
                profiler.start_monitoring()
                
                from app.cache_optimized import MemoryAwareCache
                
                # åˆ›å»ºå†…å­˜é™åˆ¶çš„ç¼“å­˜
                cache = MemoryAwareCache(max_memory_mb=50.0, max_entries=500)
                
                profiler.take_snapshot("after_cache_init")
                
                # åˆ›å»ºå¤§é‡ç¼“å­˜æ•°æ®
                for i in range(1000):
                    key = f"test_key_{i}"
                    value = {
                        "data": np.random.random(1000).tolist(),
                        "metadata": {"index": i, "timestamp": time.time()},
                        "large_text": "x" * 1000
                    }
                    
                    cache.set("test", key, value, ttl_sec=3600)
                    
                    if i % 100 == 0:
                        profiler.take_snapshot(f"after_{i}_entries")
                        stats = cache.get_stats()
                        print(f"      ç¼“å­˜ç»Ÿè®¡ ({i}): {stats['entries_count']}æ¡ç›®, "
                              f"{stats['memory_usage_mb']:.1f}MB")
                
                profiler.take_snapshot("after_all_cache_operations")
                
                # è·å–æœ€ç»ˆç»Ÿè®¡
                final_stats = cache.get_stats()
                print(f"    æœ€ç»ˆç¼“å­˜ç»Ÿè®¡: {final_stats}")
                
                # æ¸…ç†
                cache.shutdown()
                del cache
                gc.collect()
                profiler.take_snapshot("after_cleanup")
            
            peak = profiler.get_peak_memory()
            growth = profiler.get_memory_growth()
            
            results["optimized"] = {
                "peak_memory_mb": peak.rss_mb,
                "memory_growth_rate": growth,
                "success": True,
                "final_stats": final_stats
            }
            
            print(f"    ä¼˜åŒ–ç¼“å­˜å³°å€¼å†…å­˜: {peak.rss_mb:.1f} MB")
            
        except Exception as e:
            print(f"    âŒ ä¼˜åŒ–ç¼“å­˜æµ‹è¯•å¤±è´¥: {e}")
            results["optimized"] = {"success": False, "error": str(e)}
        
        # è®¡ç®—æ”¹è¿›
        if results.get("traditional", {}).get("success") and results.get("optimized", {}).get("success"):
            traditional_peak = results["traditional"]["peak_memory_mb"]
            optimized_peak = results["optimized"]["peak_memory_mb"]
            memory_reduction = traditional_peak - optimized_peak
            reduction_percent = (memory_reduction / traditional_peak) * 100
            
            results["improvement"] = {
                "memory_reduction_mb": memory_reduction,
                "reduction_percent": reduction_percent
            }
            
            print(f"    ğŸ’¡ ç¼“å­˜å†…å­˜å‡å°‘: {memory_reduction:.1f} MB ({reduction_percent:.1f}%)")
        
        return results
    
    def test_cache_performance(self) -> Dict:
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        print("\nâš¡ æµ‹è¯•ç¼“å­˜æ€§èƒ½...")
        
        results = {}
        
        try:
            from app.cache_optimized import MemoryAwareCache
            
            # åˆ›å»ºç¼“å­˜å®ä¾‹
            cache = MemoryAwareCache(max_memory_mb=100.0, max_entries=1000)
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            test_data = {}
            for i in range(500):
                key = f"perf_test_{i}"
                value = {
                    "data": np.random.random(100).tolist(),
                    "index": i,
                    "timestamp": time.time()
                }
                test_data[key] = value
            
            # æµ‹è¯•å†™å…¥æ€§èƒ½
            start_time = time.time()
            for key, value in test_data.items():
                cache.set("performance", key, value)
            write_time = time.time() - start_time
            
            # æµ‹è¯•è¯»å–æ€§èƒ½
            start_time = time.time()
            hit_count = 0
            for key in test_data.keys():
                result = cache.get("performance", key)
                if result is not None:
                    hit_count += 1
            read_time = time.time() - start_time
            
            # æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡
            hit_rate = hit_count / len(test_data)
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = cache.get_stats()
            
            results = {
                "write_time_sec": write_time,
                "read_time_sec": read_time,
                "hit_rate": hit_rate,
                "entries_count": stats["entries_count"],
                "memory_usage_mb": stats["memory_usage_mb"],
                "cache_hit_rate": stats["hit_rate"],
                "success": True
            }
            
            print(f"    å†™å…¥æ—¶é—´: {write_time:.3f}ç§’")
            print(f"    è¯»å–æ—¶é—´: {read_time:.3f}ç§’")
            print(f"    å‘½ä¸­ç‡: {hit_rate:.2%}")
            print(f"    å†…å­˜ä½¿ç”¨: {stats['memory_usage_mb']:.1f}MB")
            
            # æ¸…ç†
            cache.shutdown()
            
        except Exception as e:
            print(f"    âŒ ç¼“å­˜æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            results = {"success": False, "error": str(e)}
        
        return results
    
    def test_cache_lru_behavior(self) -> Dict:
        """æµ‹è¯•ç¼“å­˜LRUè¡Œä¸º"""
        print("\nğŸ”„ æµ‹è¯•ç¼“å­˜LRUè¡Œä¸º...")
        
        results = {}
        
        try:
            from app.cache_optimized import MemoryAwareCache
            
            # åˆ›å»ºå°å®¹é‡ç¼“å­˜
            cache = MemoryAwareCache(max_memory_mb=5.0, max_entries=10)
            
            # å¡«å……ç¼“å­˜åˆ°å®¹é‡é™åˆ¶
            for i in range(15):  # è¶…è¿‡æœ€å¤§æ¡ç›®æ•°
                key = f"lru_test_{i}"
                value = {"data": "x" * 1000, "index": i}  # æ¯ä¸ªçº¦1KB
                cache.set("lru", key, value)
            
            # æ£€æŸ¥ç¼“å­˜çŠ¶æ€
            stats = cache.get_stats()
            print(f"    ç¼“å­˜æ¡ç›®æ•°: {stats['entries_count']} (æœ€å¤§: 10)")
            print(f"    å†…å­˜ä½¿ç”¨: {stats['memory_usage_mb']:.1f}MB (æœ€å¤§: 5.0MB)")
            
            # æµ‹è¯•LRUæ·˜æ±°ï¼šè®¿é—®æ—©æœŸçš„æ¡ç›®åº”è¯¥è¢«æ·˜æ±°
            early_key_exists = cache.get("lru", "lru_test_0") is not None
            late_key_exists = cache.get("lru", "lru_test_14") is not None
            
            results = {
                "final_entries": stats['entries_count'],
                "final_memory_mb": stats['memory_usage_mb'],
                "early_key_evicted": not early_key_exists,
                "late_key_preserved": late_key_exists,
                "lru_working": not early_key_exists and late_key_exists,
                "success": True
            }
            
            print(f"    æ—©æœŸé”®è¢«æ·˜æ±°: {not early_key_exists}")
            print(f"    æ™šæœŸé”®è¢«ä¿ç•™: {late_key_exists}")
            print(f"    LRUæ­£å¸¸å·¥ä½œ: {results['lru_working']}")
            
            # æ¸…ç†
            cache.shutdown()
            
        except Exception as e:
            print(f"    âŒ LRUæµ‹è¯•å¤±è´¥: {e}")
            results = {"success": False, "error": str(e)}
        
        return results
    
    def run_cache_optimization_tests(self) -> Dict:
        """è¿è¡Œæ‰€æœ‰ç¼“å­˜ä¼˜åŒ–æµ‹è¯•"""
        print("ğŸ” ç¼“å­˜ç­–ç•¥å†…å­˜ä¼˜åŒ–æµ‹è¯•")
        print("=" * 60)
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        memory_results = self.test_cache_memory_management()
        performance_results = self.test_cache_performance()
        lru_results = self.test_cache_lru_behavior()
        
        self.results = {
            "memory_management": memory_results,
            "performance": performance_results,
            "lru_behavior": lru_results
        }
        
        self.print_optimization_summary()
        return self.results
    
    def print_optimization_summary(self):
        """æ‰“å°ä¼˜åŒ–æ•ˆæœæ‘˜è¦"""
        print("\nğŸ“Š ç¼“å­˜ä¼˜åŒ–æ•ˆæœæ‘˜è¦:")
        print("=" * 60)
        
        memory_results = self.results.get("memory_management", {})
        if "improvement" in memory_results:
            improvement = memory_results["improvement"]
            print(f"å†…å­˜ç®¡ç†ä¼˜åŒ–:")
            print(f"  å†…å­˜å‡å°‘: {improvement['memory_reduction_mb']:.1f} MB")
            print(f"  ä¼˜åŒ–å¹…åº¦: {improvement['reduction_percent']:.1f}%")
        
        performance_results = self.results.get("performance", {})
        if performance_results.get("success"):
            print(f"æ€§èƒ½æµ‹è¯•ç»“æœ:")
            print(f"  ç¼“å­˜å‘½ä¸­ç‡: {performance_results['hit_rate']:.2%}")
            print(f"  å†…å­˜ä½¿ç”¨: {performance_results['memory_usage_mb']:.1f}MB")
        
        lru_results = self.results.get("lru_behavior", {})
        if lru_results.get("success"):
            print(f"LRUè¡Œä¸ºæµ‹è¯•:")
            print(f"  LRUæœºåˆ¶æ­£å¸¸: {lru_results['lru_working']}")
            print(f"  å†…å­˜æ§åˆ¶æœ‰æ•ˆ: {lru_results['final_memory_mb']:.1f}MB â‰¤ 5.0MB")
        
        print("\nğŸ¯ ä¼˜åŒ–å»ºè®®:")
        print("1. ä½¿ç”¨å†…å­˜æ„ŸçŸ¥çš„ç¼“å­˜ç³»ç»Ÿ")
        print("2. å®ç°LRUæ·˜æ±°ç­–ç•¥")
        print("3. è®¾ç½®åˆç†çš„å†…å­˜å’Œæ¡ç›®é™åˆ¶")
        print("4. å®šæœŸæ¸…ç†è¿‡æœŸå’Œä½ä»·å€¼ç¼“å­˜")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” ç¼“å­˜ç­–ç•¥å†…å­˜ä¼˜åŒ–æµ‹è¯•å·¥å…·")
    print("=" * 60)
    
    # è¿è¡Œä¼˜åŒ–æµ‹è¯•
    test = CacheOptimizationTest()
    results = test.run_cache_optimization_tests()
    
    # ä¿å­˜ç»“æœ
    import json
    with open("cache_optimization_results.json", "w") as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: cache_optimization_results.json")

if __name__ == "__main__":
    main()
